{
  "name": "Bugreport-Agent",
  "nodes": [
    {
      "parameters": {
        "promptType": "define",
        "text": "=Your task is to create bugreport based on the analysis of the logfile. Use the following structure to create bugreports:\n\n1. Title/Bug ID:\nA short, specific title that clearly identifies the bug.\nA unique Bug ID helps track and manage the bug. \n2. Description:\nA detailed explanation of the bug, including what's expected and what actually happens.\nExplain the impact of the bug on the user experience. \n3. Steps to Reproduce:\nClear, step-by-step instructions on how to recreate the bug.\nInclude all necessary actions, clicks, or inputs. \n4. Expected vs. Actual Results:\nClearly state what you expected to happen after following the reproduction steps.\nDescribe the actual outcome, including any error messages. \n5. Environment:\nInformation about the software, operating system, browser, or device where the bug was found.\nInclude relevant configuration settings. \n\n",
        "options": {
          "returnIntermediateSteps": true
        }
      },
      "type": "@n8n/n8n-nodes-langchain.agent",
      "typeVersion": 1.9,
      "position": [
        -100,
        -180
      ],
      "id": "57f27f74-56ba-47dc-aeaa-e6de9c67ecd1",
      "name": "Bugreport-Creator"
    },
    {
      "parameters": {
        "inputSource": "passthrough"
      },
      "type": "n8n-nodes-base.executeWorkflowTrigger",
      "typeVersion": 1.1,
      "position": [
        -340,
        -180
      ],
      "id": "cea7fe84-c340-45ee-aaba-60dd7cc6503a",
      "name": "When Executed by Manager"
    },
    {
      "parameters": {
        "model": "llama3.2:latest",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "typeVersion": 1,
      "position": [
        -140,
        40
      ],
      "id": "e486a78e-990d-4cc5-86e8-dc3dfa196557",
      "name": "Ollama Chat Model",
      "credentials": {
        "ollamaApi": {
          "id": "xHuYe0MDGOs9IpBW",
          "name": "Local Ollama service"
        }
      }
    },
    {
      "parameters": {
        "sessionIdType": "customKey",
        "sessionKey": "1234"
      },
      "type": "@n8n/n8n-nodes-langchain.memoryBufferWindow",
      "typeVersion": 1.3,
      "position": [
        0,
        40
      ],
      "id": "bda91661-8db7-4b32-acb1-d93d1b90113b",
      "name": "Simple Memory"
    }
  ],
  "pinData": {},
  "connections": {
    "Bugreport-Creator": {
      "main": [
        []
      ]
    },
    "When Executed by Manager": {
      "main": [
        [
          {
            "node": "Bugreport-Creator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Ollama Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Bugreport-Creator",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Simple Memory": {
      "ai_memory": [
        [
          {
            "node": "Bugreport-Creator",
            "type": "ai_memory",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "54676668-75e5-4b72-8ad3-6a359f997aff",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "558d88703fb65b2d0e44613bc35916258b0f0bf983c5d4730c00c424b77ca36a"
  },
  "id": "SgmPFKoRyQXLAOLu",
  "tags": []
}